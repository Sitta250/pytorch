{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsxC7F10tUOYoNo5Se+zGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sitta250/pytorch/blob/main/04_pytorch_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tachjU1PEcC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "A061RQiRSMM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get data from Food101 dataset\n",
        "# 1000img: 750 training and 250 testing\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steack_sushi\"\n",
        "\n",
        "# if img folder doesn't exist, already existed\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} dir already existed. skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# download\n",
        "with open(data_path/ \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  requests = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(requests.content)\n",
        "\n",
        "# unzip data\n",
        "with zipfile.ZipFile(data_path/ \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"unzipping pizza, steak, sushi data\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "BUOFplhASm5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data prepping\n",
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filename in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filename)} images in '{dir_path}\")\n"
      ],
      "metadata": {
        "id": "MM2NzwhZUWWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "3rFr0dCJYKzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup train and testing path\n",
        "train_dir = image_path/ \"train\"\n",
        "test_dir = image_path/ \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "Y90EHCXQYM5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# get img path path\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# pick a random path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# extract img class = name of directory\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# open img\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# print metadata\n",
        "print(f\"random img path: {random_image_path}\")\n",
        "print(f\"image class: {image_class}\")\n",
        "print(f\"image height: {img.height}\")\n",
        "print(f\"image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "5ql4Dgv7ZDJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# turn img to array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# plot img with plt\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"image class: {image_class} | image shape: {img_as_array.shape} -> [height, width, color channel]\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "RmKOqJ6aakoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_as_array"
      ],
      "metadata": {
        "id": "faMpy962iZYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "5-ICp8CdjTRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write a transform for img\n",
        "data_transform = transforms.Compose([\n",
        "    # resize img to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # flip img randomly on horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # turn img to tensor\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "1d4XDbh4kO5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).dtype"
      ],
      "metadata": {
        "id": "nH2OjmAslTLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "s58k6Xcx8Ei2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_img(image_paths, transform, n=3, seed=None):\n",
        "  \"\"\"\n",
        "  select random img from path of img and load/transform then plot original vs transformed\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "  random_image_paths = random.sample(image_paths, k=n)\n",
        "  for image_path in random_image_paths:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows = 1, ncols= 2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"original\\nsize:{f.size}\")\n",
        "      ax[0].axis(False)\n",
        "\n",
        "      # transform and plot target image\n",
        "      transformed_image = transform(f).permute(1, 2, 0) # keep in mind that this will return color first but plt wants color at last position so we need to use .permute()\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transfomred\\nsize:{transformed_image.shape}\")\n",
        "      ax[1].axis(\"off\")\n",
        "\n",
        "      fig.suptitle(f\"class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_img(image_paths=image_path_list,\n",
        "                     transform=data_transform,\n",
        "                     n=3,\n",
        "                     seed=42)"
      ],
      "metadata": {
        "id": "HuIKfYWOlhnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option1: loading using ImageFolder\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "-nAqovcyngU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get class name as list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "oC2UDrjKuRm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "xzcaraLwvIJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "VTo5e2TdvcuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "MtCeuIR3vm_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index on train_data dataset to get single img and label\n",
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"image tensor:\\n {img}\")\n",
        "print(f\"image shape: {img.shape}\")\n",
        "print(f\"image datatype: {img.dtype}\")\n",
        "print(f\"image label: {label}\")\n",
        "print(f\"data datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "lUHp1Z0qvrCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_permute = img.permute(1,2,0)\n",
        "\n",
        "# print out shape\n",
        "print(f\"original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"img permute: {img_permute.shape} -> [height, width, color]\")\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14)"
      ],
      "metadata": {
        "id": "-hKBJuJ9wOic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[label]"
      ],
      "metadata": {
        "id": "Pry409WlwdMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "metadata": {
        "id": "_KR6Pevv051_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn train and test dataset ino DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=1,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=1,\n",
        "                          shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "wiHSYJKzwfKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "vSedCijV1iRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "bXWBVMOP1pE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"img shape: {img.shape}-> [batch_size, color, height, width]\")\n",
        "print(f\"label shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "gN4bvD6y11F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option2: loading data with Custom Dataset\n",
        "\n",
        "# pro: can create Dataset out of anything, not limited to prebuilt 'Dataset' function\n",
        "\n",
        "# cons: doesn't guarantee that Dataset will always work, prone to errors or performance issues\n",
        "\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "5Xde-eCa2cq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "6eqNbhSoKRGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create helper func to get class names\n",
        "# get class name using os.scandir() and raise error if class name aren't found\n",
        "\n",
        "\n",
        "# setup path for target directory\n",
        "target_directory = train_dir\n",
        "\n",
        "#get class name\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "BD4y4biWKgSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "cYa-yr2pLtuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str)->Tuple[List[str], Dict[str,int]]:\n",
        "  # get class name\n",
        "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"couldn't find any classes in {directory}... please check file structure\")\n",
        "\n",
        "  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "9y8bmDBZMffm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "BBkbzcxVNE6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom Dataset\n",
        "# subclass torch.utils.data.Dataset\n",
        "'''\n",
        "create several attributes:\n",
        "- paths - paths for img\n",
        "- transform\n",
        "- classes - list of target class\n",
        "- class_to_idx\n",
        "'''\n",
        "\n",
        "class ImageFolderCustom(Dataset):\n",
        "  def __init__(self,\n",
        "               targ_dir:str,\n",
        "               transform=None):\n",
        "    self.paths=list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
        "    # setup transform\n",
        "    self.transform = transform\n",
        "    # create classes and class_to_idx attributes\n",
        "    self.classes, self.class_to_idx=find_classes(targ_dir)\n",
        "    # load img\n",
        "  def load_image(self, index: int) -> Image.Image:\n",
        "    \"Opens an image via a path and returns it\"\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  # overwrite__len__()\n",
        "  def __len__(self)->int:\n",
        "    \"return the total number of samples\"\n",
        "    return len(self.paths)\n",
        "\n",
        "  # overwrite __getitem__() method to return a particular sample\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.Tensor,int]:\n",
        "    \"Return one sample of data, data and label (X, y)\"\n",
        "    img = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    # transform when necessary\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx\n",
        "    else:\n",
        "      return img, class_idx\n"
      ],
      "metadata": {
        "id": "nj-plmgWNH4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create transform\n",
        "from torchvision import transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "mBzZ4HwUZMC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom = ImageFolderCustom(targ_dir=train_dir,\n",
        "                                      transform = train_transforms)\n",
        "test_data_custom = ImageFolderCustom(targ_dir=test_dir,\n",
        "                                     transform=test_transforms)"
      ],
      "metadata": {
        "id": "alEKR22waM0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(train_data_custom)"
      ],
      "metadata": {
        "id": "2nlXxeDNaxuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(test_data_custom)"
      ],
      "metadata": {
        "id": "J61lV9Pjd07e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "DmV5OsnYfeX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "zIYJ_EG3fhjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_custom.classes==train_data.classes)\n",
        "print(test_data_custom.classes==test_data.classes)"
      ],
      "metadata": {
        "id": "QGLmAukxfzZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "XLK8v9bnOoNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display random image\n",
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                          classes:List[str]=None,\n",
        "                          n: int=10,\n",
        "                          display_shape:bool=True,\n",
        "                          seed: int = None):\n",
        "  if n>10:\n",
        "    n=10\n",
        "    display_shape=False\n",
        "    print(f\"for display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display\")\n",
        "\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "\n",
        "  random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "  rows=2\n",
        "  cols=math.ceil(n/rows)\n",
        "  plt.figure(figsize=(cols*3, rows*3))\n",
        "\n",
        "  for i, targ_sample in enumerate(random_samples_idx):\n",
        "    targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "    targ_image_adjust = targ_image.permute(1,2,0)\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(targ_image_adjust)\n",
        "    plt.axis(\"off\")\n",
        "    if classes:\n",
        "      title= f\"classes:{classes[targ_label]}\"\n",
        "      if display_shape:\n",
        "        title=title+ f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "ShryLxJRgHnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display from ImageFolder\n",
        "display_random_images(train_data,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=42)"
      ],
      "metadata": {
        "id": "WuCdgp3Qoxkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display from custom dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      n=20,\n",
        "                      classes=class_names,\n",
        "                      seed=42)"
      ],
      "metadata": {
        "id": "rj1oLdu9NlRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn custom loaded images into DataLoader\n",
        "BATCH_SIZE=32\n",
        "train_dataloader_custom = DataLoader(dataset = train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=0,\n",
        "                                     shuffle=True)\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    num_workers=0,\n",
        "                                    shuffle=False)\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "pZ0QWD0sPP8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "8OfaWsVfQVax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation\n",
        "\n",
        "# trivial augment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "LO-joRx5Qgc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "0uc4YAP_T8dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_transformed_img(\n",
        "    image_paths = image_path_list,\n",
        "    transform=train_transform,\n",
        "    n=3,\n",
        "    seed=None\n",
        ")"
      ],
      "metadata": {
        "id": "3L6LtedeUGhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 0: TinyVGG without data augmentation\n",
        "# conv -> relu -> conv -> relu -> maxpool\n",
        "\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=simple_transform)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=simple_transform)\n",
        "print(f\"train:{train_data} \\n test:{test_data}\")"
      ],
      "metadata": {
        "id": "6pKKcgu5Urss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset to dataloader\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "train_dataloader_simple = DataLoader(dataset=train_data_simple,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=True)\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    num_workers=NUM_WORKERS,\n",
        "                                    shuffle=False)\n",
        "print(f\"train: {train_dataloader_simple} \\n test:{test_dataloader_simple}\")"
      ],
      "metadata": {
        "id": "ZdzdGuHJXUkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*16*16,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv_block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-xIO8is7YXkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "e67G6ybKwuRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try forward pass on single image to see the shape\n",
        "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "X1mWN7ltxKiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(image_batch)"
      ],
      "metadata": {
        "id": "BQKO7JrXxks8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0, input_size=[1, 3, 64, 64])"
      ],
      "metadata": {
        "id": "Z5iPiLj0zQwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metrics across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "zd-jyuGjy57V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        # Ensure all data is moved to CPU and converted to float for storage\n",
        "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "nQYtjolC4Pgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "z5U5EQnZ7Hwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "JOGN15n3Dj1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss curve\n",
        "model_0_results.keys()"
      ],
      "metadata": {
        "id": "nrSl2ZoNQCvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    accuracy = results['train_acc']\n",
        "    test_accuracy = results['test_acc']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();"
      ],
      "metadata": {
        "id": "5CmzoJYJQd-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_0_results)"
      ],
      "metadata": {
        "id": "pbYaWcCQRU2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tiny vgg with data augmentation\n",
        "\n",
        "train_transform_trivial = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms_ismple = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "a4V2eFbSSI-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test dataset and dataloader with data augmentation\n",
        "train_data_augmented = datasets.ImageFolder(root=train_dir,\n",
        "                                            transform=train_transform_trivial,\n",
        "                                            )\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                        transform=test_transforms_ismple)"
      ],
      "metadata": {
        "id": "BRkOuQjAbwpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn to dataloader\n",
        "import os\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_datalaoder_augmented = DataLoader(dataset = train_data_augmented,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=NUM_WORKERS)\n",
        "test_dataloader_simple = DataLoader(dataset = test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "R-z9nNSWcehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_1=TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data_augmented.classes)\n",
        ").to(device)\n",
        "\n",
        "model_1"
      ],
      "metadata": {
        "id": "ncHOEvtodIm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "NUM_EPOCHS=5\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "model_1_results = train(model=model_1,\n",
        "                        train_dataloader = train_datalaoder_augmented,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"total training time for model 1: {end_time -start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "JAmMc2akeAHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1:00:31:43"
      ],
      "metadata": {
        "id": "FDXvXSKrfEtZ"
      }
    }
  ]
}