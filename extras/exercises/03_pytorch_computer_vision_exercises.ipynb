{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sitta250/pytorch/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GaeYzOTLwWh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n"
      ],
      "metadata": {
        "id": "DNwZLMbCzJLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- manufacturing for quality control\n",
        "- healthcare for medical imaging analysis and diagnostics\n",
        "- automotive industry for autonomous vehicles and driver-assisance systems"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- overfitting in ML occurs when a model learns a training data too well, including its noise and outliers, resulting in poor performance on new, unseen data."
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- increase training data\n",
        "- simplify model\n",
        "- use regularization\n",
        "- cross validation"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "1PNhgUcUqVRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "2PI0qqsxLXN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "JTRrK6AGtr79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "print(f\"length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "aGifIv6UuCi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9xmVlSHNLqBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(nn.Module):\n",
        "  def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2), #28->14\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2), #14->7\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "GCB6FdtfAuvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "ZoaljwjQBECo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "4NlDznwMBn0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_1 = MNISTModel(input_shape = 1,\n",
        "                     hidden_units=10,\n",
        "                     output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "W0qx-AlHAmAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q torchmetrics -U mlxtend"
      ],
      "metadata": {
        "id": "LlCTCHyUDrPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics"
      ],
      "metadata": {
        "id": "tqBFU4J8EIM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn, acc_fn, optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_names)).to(device)\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "5Xm0PmBoCxw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device= None):\n",
        "  total_time = start - end\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "074qr93JDREi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm"
      ],
      "metadata": {
        "id": "ckVLkR0bFhVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"epoch: {epoch}\\n---------\")\n",
        "\n",
        "  train_loss = 0\n",
        "  for batch, (X, y)  in enumerate(train_dataloader):\n",
        "    model_1.train()\n",
        "    y_pred = model_1(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch%400 ==0:\n",
        "      print(f\"looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  test_loss, test_acc = 0, 0\n",
        "  accuracy_fn.reset()\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in test_dataloader:\n",
        "      test_pred = model_1(X)\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      accuracy_fn.update(test_pred,y)\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc = accuracy_fn.compute()\n",
        "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:5f} | Test_acc: {test_acc:.2f}%\\n\")\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end = train_time_end_on_cpu,\n",
        "                                            device = str(next(model_1.parameters()).device))"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module, data:list, device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "      pred_logit = model(sample)\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "5GE1ZJ2NZeWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "print(f\"test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
      ],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = make_predictions(model=model_1,\n",
        "                              data = test_samples)\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "vSfBFvVLaXx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes= pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "ife6ph_9aiGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, pred_classes"
      ],
      "metadata": {
        "id": "ilUM11rfazQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "nrows=3\n",
        "ncols=3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  if pred_label == truth_label:\n",
        "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
        "  else:\n",
        "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "g6BJiIQEa46k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = []\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"making prediction\"):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_logit = model_1(X)\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
        "    y_preds.append(y_pred.cpu())\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = torchmetrics.ConfusionMatrix(num_classes = len(class_names), task='multiclass')\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(),\n",
        "    class_names=class_names,\n",
        "    figsize=(7, 5)\n",
        ")"
      ],
      "metadata": {
        "id": "XdGdEs7tcVhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 64, 64)"
      ],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = [1,3,5,11]\n",
        "\n",
        "for k in kernel_size:\n",
        "  conv_layer = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=k)\n",
        "  out = conv_layer(x)\n",
        "  print(f\"kernel size: {k} -> output shape: {out.shape}\")"
      ],
      "metadata": {
        "id": "0wiX1AEYfs8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}