{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFjuFwXuSAVoLunTyog9Ok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sitta250/pytorch/blob/main/computer_vision_with_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPTw-FwEGUaM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getting dataset"
      ],
      "metadata": {
        "id": "ZExfTZb4TwKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to store data\n",
        "    train=True, # do we train this dataset\n",
        "    download = True, # do we download dataset\n",
        "    transform=torchvision.transforms.ToTensor(), #how will we train data\n",
        "    target_transform=None #do we transform labels/ targets\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root= \"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "YSoEgY5eNZK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "Qf8ZdD4qQCY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "kuEIQ8keQW8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "2j5dUvmFQjo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "8nKcOwLKRAk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "NjpFSayRRRXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"image shape: {image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"image label: {class_names[label]}\")"
      ],
      "metadata": {
        "id": "CJA0jI-PRdjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### visualizing data"
      ],
      "metadata": {
        "id": "eF34Q2R_RjBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "print(f\"image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "CXto2s63T02X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "f-hpzi7ST-G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "HaB26cIbUb1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare DataLoader\n",
        "turn data in form of PyTorch Datasets into Python iterable, specifically we wnat batches\n",
        "- more computationally efficient to look at each batch at a time\n",
        "- give NN more change to update its gradient per epoch\n"
      ],
      "metadata": {
        "id": "Ei3qCQszU3mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#setup batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#turn dataset into iterables\n",
        "train_dataloader = DataLoader(dataset= train_data,\n",
        "                        batch_size = BATCH_SIZE,\n",
        "                        shuffle= True)\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "d8YjrdRZrWqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")"
      ],
      "metadata": {
        "id": "Ir4e1l3usrF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check what is created\n",
        "print(f\"Dataloader: {train_dataloader, test_dataloader}\")\n",
        "print(f\"length of train_dataloader: {len(train_dataloader)} | batches of {BATCH_SIZE}\")\n",
        "print(f\"length of test_dataloader: {len(test_dataloader)} | batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "xs4X_FeVs9Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "Js3JFkuBuQmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display samples\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch),size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"image size: {img.shape}\")\n",
        "print(f\"image label: {label}, label size:{label.shape}\")"
      ],
      "metadata": {
        "id": "iTiFSQEVtoNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build baseline model\n",
        "- baseline is a simple model we try to improve upon with subsequent model/ experiment\n"
      ],
      "metadata": {
        "id": "GkBPd5nFv_JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# get a single sample\n",
        "X = train_features_batch[0]\n",
        "\n",
        "output = flatten_model(X)\n",
        "\n",
        "print(f\"shape before flattening: {X.shape} ->[color channel, height, width]\")\n",
        "print(f\"shape afer flattening: {output.shape} -> [color_channel, height*width]\")"
      ],
      "metadata": {
        "id": "uYtzPBuIxrkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack= nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features = hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "byevmPz0x5QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape = 784,\n",
        "    hidden_units = 10,\n",
        "    output_shape = len(class_names)\n",
        ").to(\"cpu\")\n",
        "model_0"
      ],
      "metadata": {
        "id": "-38WHgbi02b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1,1,28, 28])\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "id": "27hx_cvL1Teu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up loss, optimizer and evaluation metrics\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# downlaod helper functions from Learn PyTorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download...\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "8h29CVmv1haV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import accuracy matric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "x8bnDYUy5sxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### two main things to track to in ML\n",
        "1. performance: accuracy and loss\n",
        "2. hot fast it runs"
      ],
      "metadata": {
        "id": "a8EOYwMK54uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  total_time = end-start\n",
        "  print(f\"Train time on {device}: {total_time: .3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "N7m0LbDB6_0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creatign training loop on data batches\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n\")\n",
        "\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    y_pred = model_0(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss+=loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch %400 ==0:\n",
        "      print(f\"looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "    # divie total train loss by length of trian dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  # test loop\n",
        "  test_loss, test_acc = 0,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      test_pred = model_0(X_test)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "      test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss/=len(test_dataloader)\n",
        "    test_acc/= len(test_dataloader)\n",
        "  print(f\"\\nTrain loss: {train_loss: .4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "train_time_end_on_cpu = timer()\n",
        "\n",
        "  # calculaAe training time\n",
        "trian_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                              end= train_time_end_on_cpu,\n",
        "                                              device=next(model_0.parameters()).device)\n",
        "\n"
      ],
      "metadata": {
        "id": "BzOkM0n07ty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(next(model_0.parameters()).device)"
      ],
      "metadata": {
        "id": "CA7ChLXXCbfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cpu\""
      ],
      "metadata": {
        "id": "GE0anAeu0-P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction and get model 0 results\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device=device):\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      y_pred = model(X)\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return{\"model_name\": model.__class__.__name__,\n",
        "         \"model_loss\": loss.item(),\n",
        "         \"model_acc\": acc}\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader = test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn = accuracy_fn)\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "KA6NG0coCnHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16:23:56"
      ],
      "metadata": {
        "id": "0uAtXrR2OeNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, input_shape:int, hidden_units: int, output_shape:int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    return self.layer_stack(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "KwwyTDRxxGFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "F5ZRjdWP2t3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(input_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "LZFu3XKd1h5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss fn and optim\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_1.parameters(),\n",
        "                             lr=0.02)"
      ],
      "metadata": {
        "id": "imnLqxUT4w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#functionizing training and evaluation/testing loop\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device=device):\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    #put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    #loss and acc per batch\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss+=loss\n",
        "    train_acc+=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # optimzer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # back prop\n",
        "    loss.backward()\n",
        "\n",
        "    # step update\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # divie total train loss and acc by length of trian dataloader\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"train loss: {train_loss:.5f} | train acc: {train_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "KO2kCLOd50F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test step\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device=device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      # find loss and acc\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true=y,\n",
        "                          y_pred = test_pred.argmax(dim=1))\n",
        "      test_loss /= len(data_loader)\n",
        "      test_acc /= len(data_loader)\n",
        "    print(f\"test loss: {test_loss:.5f} | test acc: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "eXUHtaNp9pD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"epoch: {epoch}\\n\")\n",
        "  train_step(model=model_1,\n",
        "             data_loader = train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             accuracy_fn = accuracy_fn,\n",
        "             device = device)\n",
        "\n",
        "  test_step(model=model_1,\n",
        "            data_loader= test_dataloader,\n",
        "            loss_fn= loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device = device)\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device = device)"
      ],
      "metadata": {
        "id": "zGAlL39dBcYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "enM4uP5mCw3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader= test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)"
      ],
      "metadata": {
        "id": "aRb64DAiGlvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "NYz6Zc2DPDHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        # create conv layer\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape,\n",
        "                  )\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(f\"outputshape of conv_block_1: {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(f\"outputshape of conv_block_2: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    # print(f\"outputshape of conv_classifier: {x.shape}\")\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "pPYpaESIPhCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2=FashionMNISTModelV2(input_shape=1,\n",
        "                            hidden_units=10,\n",
        "                            output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "LaxQypWiWa2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "QWw4H5FZCLqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor = torch.randn(size=(1,28, 28))\n",
        "rand_image_tensor.shape"
      ],
      "metadata": {
        "id": "y1Sa3S2dC4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(rand_image_tensor.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "nYARBIkLClgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "images = torch.randn(size=(32, 3, 64, 64))\n",
        "\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"image batch shape: {images.shape}\")\n",
        "print(f\"single image shape: {test_image.shape}\")\n",
        "print(f\"test image:\\n {test_image}\")"
      ],
      "metadata": {
        "id": "CuFQl48NkWG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.shape"
      ],
      "metadata": {
        "id": "LOzQ2S9f4ilS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# create conv2d layer\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=64,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=1)\n",
        "\n",
        "# pass data\n",
        "conv_output = conv_layer(test_image)\n",
        "conv_output.shape"
      ],
      "metadata": {
        "id": "miA3bs_62psN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"test image original shape: {test_image.shape}\")\n",
        "print(f\"test image after unsqueeze shape: {test_image.unsqueeze(0).shape}\")\n",
        "\n",
        "# sample nn.MaxPool2d layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# pass data through max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"shape after goign through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
      ],
      "metadata": {
        "id": "dJY7b1nY4cgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# create a random tensor with a similar number of dimensions to our images\n",
        "random_tensor = torch.randn(size=(1,1,2,2))\n",
        "print(f\"\\nRandom tensor:\\n{random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "# create a max pool layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# pass random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor: \\n {max_pool_tensor}\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "JJGLy48J7WNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training cnn on dataset FashionMNIST\n",
        "\n",
        "#setup loss fn/ eval metrics/ optimizer\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "pmjsbIX5_MbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "epochs=3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epochs: {epoch}\\n\")\n",
        "  train_step(model=model_2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model_2,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "  train_time_end_model_2 = timer()\n",
        "  total_train_time_model_2 = print_train_time(start= train_time_start_model_2,\n",
        "                                              end=train_time_end_model_2,\n",
        "                                              device=device)"
      ],
      "metadata": {
        "id": "dukQerdSMCIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn = loss_fn,\n",
        "    accuracy_fn=accuracy_fn,\n",
        "    device=device\n",
        ")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "GwZalwRqNoyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "WGHd_x4gRIz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparning result and training time\n",
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])"
      ],
      "metadata": {
        "id": "jltCFEShRTT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results"
      ],
      "metadata": {
        "id": "gewZpqhwRtXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add training time to result comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "AbFKfNXmRwJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\")"
      ],
      "metadata": {
        "id": "uHX85wS8VS9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data:list,\n",
        "                     devices:torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # prep sample\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      # forward pass\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # get pred prob: logit -> prediction prob with softmax\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "1hwVCOu7V4ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "lRJ46zvKY0Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "0o69epFXYN1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[test_labels[0]])"
      ],
      "metadata": {
        "id": "k1L2Z3g9ZOIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples)\n",
        "\n",
        "# view first two prediction prob\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "tFBb-PcAZWXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "no7qNTUuZ4gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot predictions\n",
        "plt.figure(figsize=(9,9))\n",
        "nrow=3\n",
        "ncols=3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # create subplot\n",
        "  plt.subplot(nrow, ncols, i+1)\n",
        "\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # get truth table\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # create title\n",
        "  title_text= f\"pred: {pred_label} | truth: {truth_label}\"\n",
        "\n",
        "  # check for equality between pred and truth and change color of title text\n",
        "  if pred_label== truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")\n",
        "\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "vNi78k4XaWNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make confusion matrix\n",
        "\n",
        "import mlxtend\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "LbrnAtKbcLdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds=[]\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"making prediction...\"):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_logit = model_2(X)\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "    y_preds.append(y_pred.cpu())\n",
        "\n",
        "print(y_pred)\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "y_pred_tensor[:10]"
      ],
      "metadata": {
        "id": "WG8t69P9hIOC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}